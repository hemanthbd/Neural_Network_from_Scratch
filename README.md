# Neural_Network_from_Scratch

Implements different layers of Neural Network- Full,Softmax,Rectified Linear Unit (ReLu), Cross Entropy Loss layer and a 
Sequential Layer which combines all the above layers.
Sequential Layer-> Merges all the individual layers and gives your Training Error Loss vs Epochs, and your Test Accuracy vs 
Learning Rate.
This is done just using 4 classes of the CIGAR-100 dataset.(Just so as to check if the layers implemented from scratch were 
good)

You can download the CIFAR-100 dataset from https://www.cs.toronto.edu/~kriz/cifar.html
